{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Training Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "spaCy’s rule-based Matcher is a great way to quickly create training data for named entity models. A list of sentences is available as the variable TEXTS. You can print it the IPython shell to inspect it. We want to find all mentions of different iPhone models, so we can create training data to teach a model to recognize them as 'GADGET'."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Write a pattern for two tokens whose lowercase forms match 'iphone' and 'x'.\n",
    "2. Write a pattern for two tokens: one token whose lowercase form matches 'iphone' and an optional digit using the '?' operator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from spacy.matcher import Matcher\n",
    "from spacy.lang.en import English"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEXT =['How to preorder the iPhone X', \n",
    "       'iPhone X is coming', \n",
    "       'Should I pay $1,000 for the iPhone X?', \n",
    "       'The iPhone 8 reviews are here', \n",
    "       'Your iPhone goes up to 11 today', \n",
    "       'I need a new phone! Any tips?']\n",
    "nlp = English()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "matcher = Matcher(nlp.vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Two tokens whose lowercase forms match 'iphone' and 'x'\n",
    "pattern1 = [{'LOWER': 'iphone'}, {'LOWER': 'x'}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Token whose lowercase form matches 'iphone' and an optional digit\n",
    "pattern2 = [{'LOWER': 'iphone'}, {'IS_DIGIT': True, 'OP': '?'}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add patterns to the matcher\n",
    "matcher.add(\"GADGET\", None, pattern1, pattern2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Bootstrap a set of training examples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Create a doc object for each text using nlp.pipe.\n",
    "2. Match on the doc and create a list of matched spans.\n",
    "3. Get (start character, end character, label) tuples of matched spans.\n",
    "4. Format each example as a tuple of the text and a dict, mapping 'entities' to the entity tuples.\n",
    "5. Append the example to TRAINING_DATA and inspect the printed data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAINING_DATA = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a Doc object for each text in TEXTS\n",
    "for doc in nlp.pipe(TEXT):\n",
    "    # Match on the doc and create a list of matched spans\n",
    "    spans = [doc[start:end] for match_id, start, end in matcher(doc)]\n",
    "    # Get (start character, end character, label) tuples of matches\n",
    "    entities = [(span.start_char, span.end_char, \"GADGET\") for span in spans]\n",
    "    # Format the matches as a (doc.text, entities) tuple\n",
    "    training_example = (doc, {\"entities\": entities})\n",
    "    # Append the example to the training data\n",
    "    TRAINING_DATA.append(training_example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(How to preorder the iPhone X, {'entities': [(20, 28, 'GADGET'), (20, 26, 'GADGET')]})\n",
      "(iPhone X is coming, {'entities': [(0, 8, 'GADGET'), (0, 6, 'GADGET')]})\n",
      "(Should I pay $1,000 for the iPhone X?, {'entities': [(28, 36, 'GADGET'), (28, 34, 'GADGET')]})\n",
      "(The iPhone 8 reviews are here, {'entities': [(4, 12, 'GADGET')]})\n",
      "(Your iPhone goes up to 11 today, {'entities': [(5, 11, 'GADGET')]})\n",
      "(I need a new phone! Any tips?, {'entities': []})\n"
     ]
    }
   ],
   "source": [
    "print(*TRAINING_DATA, sep=\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Training Neural "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setting Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Create a blank 'en' model, for example using the spacy.blank method.\n",
    "2. Create a new entity recognizer using nlp.create_pipe and add it to the pipeline.\n",
    "3. Add the new label 'GADGET' to the entity recognizer using the add_label method on the pipeline component."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp= spacy.blank('en')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "ner = nlp.create_pipe('ner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp.add_pipe(ner)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "ner.add_label('GADGET')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build a training Loop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The small set of labelled examples that you’ve created previously is available as TRAINING_DATA. To see the examples, you can print them in your script.\n",
    "\n",
    "1. Call nlp.begin_training, create a training loop for 10 iterations and shuffle the training data.\n",
    "2. Create batches of training data using spacy.util.minibatch and iterate over the batches.\n",
    "3. Convert the (text, annotations) tuples in the batch to lists of texts and annotations.\n",
    "4. For each batch, use nlp.update to update the model with the texts and annotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<thinc.neural.optimizers.Optimizer at 0x7fbf31a589b0>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp.begin_training()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ner': 12.799999833106995}\n",
      "{'ner': 24.067995309829712}\n",
      "{'ner': 31.91904306411743}\n",
      "{'ner': 9.710038661956787}\n",
      "{'ner': 13.813634246587753}\n",
      "{'ner': 17.50754678249359}\n",
      "{'ner': 3.1633437052369118}\n",
      "{'ner': 4.610809381119907}\n",
      "{'ner': 7.603855360648595}\n",
      "{'ner': 0.9206280021899147}\n",
      "{'ner': 2.5533733413349182}\n",
      "{'ner': 3.974387467026645}\n",
      "{'ner': 1.2504660709382733}\n",
      "{'ner': 2.21735084753891}\n",
      "{'ner': 9.722241501774988}\n",
      "{'ner': 0.5169736024690792}\n",
      "{'ner': 1.56973624532111}\n",
      "{'ner': 1.598955237050717}\n",
      "{'ner': 0.029113001650557635}\n",
      "{'ner': 1.1186205591604903}\n",
      "{'ner': 1.120538724588111}\n",
      "{'ner': 0.00025163989943699505}\n",
      "{'ner': 1.0078574750490983}\n",
      "{'ner': 1.0079279419797198}\n",
      "{'ner': 2.3430478067130025}\n",
      "{'ner': 2.3430594575857686}\n",
      "{'ner': 2.3430698325725996}\n",
      "{'ner': 1.1493791369139217}\n",
      "{'ner': 1.1493840977427456}\n",
      "{'ner': 1.1493871128783053}\n"
     ]
    }
   ],
   "source": [
    "for itn in range(10):\n",
    "    random.shuffle(TRAINING_DATA)\n",
    "    losses = {}\n",
    "    for batch in spacy.util.minibatch(TRAINING_DATA,size=2):\n",
    "        texts = [text for text, entities in batch]\n",
    "        annotations = [entities for text, entities in batch]\n",
    "        nlp.update(texts,annotations,losses=losses)\n",
    "        print(losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7142857142857143"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "5/7"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
